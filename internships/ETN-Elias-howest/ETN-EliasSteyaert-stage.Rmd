---
title: "ETN_EliasSteyaert-stage"
author: "Elias Steyaert"
date: "2024-04-23"
output: pdf_document
---

# Electronic traineeship notebook (ETN) - Elias Steyaert 
### A logbook that describes what happened on a daily basis.
### Link to my github:
https://github.com/EliasSteyaert/stage-VIB-irefindex

## Week 1
#### Monday 22/04/2023

##### Exploring the main project for the following weeks:
- Explore the github repository of the project (https://github.com/vibbits/irefindex)
- Read article about the iRefIndex (Razick, S., Magklaras, G., & Donaldson, I. M. (2008). iRefIndex: A consolidated protein interaction database with provenance. BMC Bioinformatics, 9(1), 405. https://doi.org/10.1186/1471-2105-9-405)
- Read documentation on the iRefIndex (https://irefindex.vib.be/wiki/index.php/iRefIndex)
- Explore the scripts to be used 

##### Preparation for the project:
- Making an account on csv
- Downloading and installing the needed programs and having a look at how to use these (ansible, terraform and nextflow).


#### Tuesday 23/04/2023

##### Exploring the main project: 
- Explore the github repository of the project even further (https://github.com/vibbits/irefindex)

##### Preparation for the project:
- Getting the csv account fully setup after getting it approved (with a ssh key)
- Trying to get past the “13000 gate” with VPN’s. (Setting up a KULeuven- and a UGent-VPN)
- Learning more about ansible and terraform through tutorials and "how-to's"
- Exploring the ansible code with the newly requiered knowledge from earlier.


#### Wednesday 24/04/2023

##### Trying to setup the needed resources through terraform:
- Setting up the vsc connection (solving troubleshooting for errors for “terraform init” in the VM
- Setting up the identifcation credentials on the VSC_2021_102 cloud
- Running into troubleshooting while deleting the previous instance and volume

##### Setting up a github repository
- Forking and cloning the VIB github repository into my own and setting up the needed folders/files into it (https://github.com/EliasSteyaert/stage-VIB-irefindex)


#### Thursday 25/04/2023

##### Performing the "terraform-step" of the procedure:
- Running into troubleshooting for the whole day when trying to perform the command "terraform apply -auto-approve"
- Been getting a lot of different errors and finding different solutions which don't work

##### side-tasks to do while waiting for the task to be executed:
- Making the ETN Markdown file and complement it with the things that are performed till this day
- Making a troubleshooting file and filling in all the issueas that were encountered so far


#### Friday 26/04/2023

##### Trying to perform "terraform apply"
- Trying to solve the problems that occur when performing “terraform apply”, trying to get the instance and its volume working. 

##### Learning more about the Vlaamse Super Computer
- Learning more about instances and their volumes, what they are, how thet are used. 
Making an instance and a volume manually and connecting them with eachother. 
Connecting to the instance. 

##### Playing the first playbook


## Week 2
#### Monday 29/04/2024

##### Running the playbook 
- Run the playbook untill I get an error that needs to be solved. (main1 and after_main1 could be ran, main2 gave problems). 

##### Solving minor problems
- Deleting all the data in google cloud. 
- Making a new directory to store everything in. 


#### Tuesday 30/04/2024

##### Problem-soloving the Irdownload playbook
- Irdownload doesn’t work anymore so we will be adjusting the irdata-config so it can work again.  


#### Wednesday 01/05/2024

##### Labours day


#### Thursday 02/05/2024

##### Problem-solving the Irunpack playbook
- Running into problems when performing the Irunpack playbook, existing_dirs wasn’t defined and the location of the files were wrong

##### Problem-solving the Irparse playbook
- Running into problems when performing the Irparse playbook, pip3 has to be installed with apt, not dnf 


#### Friday 03/05/2024

##### Problem-solving new problems the Irparse playbook brings with it
- Running into new problems while running the irparse playbook: creating a venv and trying to get the irdata package downloaded 


## Week 3
#### Monday 06/05/2024

##### Problem-solving new problems the Irparse playbook brings with it
- Running into different kinds of problems when running the irparse playbook. The error says that the space is full but that doesn’t seem to be the problem. 
- Adding a python interpreter as an environment for the .py scripts


#### Thursday 07/05/2024

##### Problem-solving new problems the Irparse playbook brings with it
- Being stuck on the irparse.yml playbook. 
- Trying to figure out how to solve the “need more space” error.


#### Wednesday 08/05/2024

##### Problem-solving new problems the Irparse playbook brings with it
- Creating a "for loop" to get the python interpreter into the scripts which need the environment to solve “from irdata import data ModuleNotFoundError: No module named 'irdata'” 
```bash
for filename in $(grep -rl "TOOLS" ./usr/bin/* | sort | uniq); do 
cat "$filename" | sed "s|\(\$TOOLS/.*.py\)|\${USE_PYTHON_INTERPRETER}\" \"\1|g"
> "$filename.tmp" && mv "$filename.tmp" "$filename"; done
```

#### Thursday 09/05/204

##### Ascension Day 


#### Friday 10/05/2024

##### Problem-solving new problems the Irparse playbook brings with it
- Trying to expand the disk space to solve the problem of “need more space”. Doing so I messed up the server by trying to make a new partition. 
- I made the server crash. Alex setted up a new server. The IP-adress in the file "inventory" must be updated to the new one. To get the /mnt/disks/data back (linked to the /dev/sda), I followed the following site of google itself: https://cloud.google.com/compute/docs/disks/format-mount-disk-linux
After the /mnt/disks/data was set-up, the playbook could be played from my VM onto the google cloud instance.


## Week 4
#### Monday 13/05/2024

##### Playing the playbook all over again
- Starting over again with the playbook: changing the inventory, playing main1.yml, after_main1.yml and main2.yml till it got stuck at irparse.yml 

##### Problem-solving new problems the Irparse playbook brings with it
- Trying to find a solution for the "from irdata import data as irdt ModuleNotFoundError: No module named 'irdata'"


#### Tuesday 14/05/2024

##### Problem-solving new problems the Irparse playbook brings with it
- Trying to get the Irparse.yml running 
- Learning more about binairy and how a kernel works. Learning more about the hashbang, how it works and why it is there. 


#### Wednesday 15/05/2024

##### Problem-solving new problems the Irparse playbook brings with it
- Looking for a solution to get Irparse.yml running with the knowledge of the day before.
- Running into a new error: "/home/irefindex/usr/bin/irdata_parse_bind.sh: line 94: : command not found" where the line it references is a line with the python interpreter.
- Trying little things like installing pip into the environment, even though it should be already there


#### Thursday 16/05/2024

##### Problem-solving new problems the Irparse playbook brings with it
- Making a smaller version of the ansible playbook where the same error occurs so it’s easier to try to get the error out of the script. To test this, an ansible playbook was made(.yml). This playbook executed a bash script (.sh) which on it's part executed a python script (.py) where the irdata module could be found in. 
- Trying multiple things to fix the script but failing so. 


#### Friday (17/05/2024)

##### Problem-solving new problems the Irparse playbook brings with it
- Trying to get all the jobs running 

##### Downloading the "mint" database
- Making a sources2.yml where only mint is present so it can be downloaded quicker and the errors are better logged.
- Making the download work after seeing where the error occurs (the link had to be updated).


## Week 5
#### Monday (20/05/2024)

##### Pentecostmonday


#### Tuesday (21/05/2024)

##### Irdownload for the databases that didn't work before
- Fully downloading the mint database 
- Trying to get the irdownload running for “ipi”, “bar”, “corumdb” and “matrixdb” 

##### Fixing the “Irdata” problem 
- Problem-solving the irdata "module not found" further on the basis of the mini-version of the scripts
- Learning more about the subprocess module: what it is and what it is used for (https://docs.python.org/3/library/subprocess.html)


#### Wednesday (22/05/2024)

##### Learning more about the individual aspects of the scripts
- Figuring out what “dir” does, why it is usefull and how it is used 

##### Fixing the irpase playbook
- Finally fixing the irparse playbook so the "irmodule irdata could not be found" error is solved
- Piece of code that installed the irdata, with this solution, every .sh script where irdata is being used needs to be in the virtual environment:
```bash
    - name: Ensure python3-venv and python3-pip are installed
      ansible.builtin.apt:
        name:
          - python3-venv
          - python3-pip
        state: present

    - name: Create virtual environment
      ansible.builtin.command:
        cmd: python3 -m venv "{{ download_data }}/{{ data2 }}/virtualenv"
      args:
        creates: "{{ download_data }}/{{ data2 }}/virtualenv"

    - name: install irdata
      ansible.builtin.command:
        cmd: "{{ download_data }}/{{ data2 }}/virtualenv/bin/python3 -m pip install irdata"  
```

##### Parsing the job "Athelian"
- With the knowledge that the smaller version of the playbook which I made earlier works, I can adjust the process of parsing "Athelian
- Figuring out how to get the job “Athelian” to get parsed and get passed the error 


#### Thursday (23/05/2024)
 
##### Running the irparse playbook
- Running the jobs one by one, fixing the easy errors and logging the harder errors. 

 
#### Friday (24/05/2024)

##### Fixing a parsing error
- Investigating the error: mkdir: cannot create directory '/home/elias.steyaert/.ansible/tmp/ansible-tmp-1716456592.068384-36656-83367091344262': No space left on device
- This was fixed with making an ansible.cfg file with the code 
```bash 
“remote_tmp = /mnt/disks/data 
```
- Investigating the error: 
```bash
"sh: 1: Syntax error: Unterminated quoted string" 
```

## Week 6
#### Monday (27/05/2024)

##### Fixing the parsing step of the job “refseq” 
- The error "sh: 1: Syntax error: Unterminated quoted string" occured and looking for a fix for that
- Figuring out how the irparallel script works 


#### Tuesday (28/05/2024)

##### Getting the irparallel script to work together with the jobs genpept, refseq and uniprot. 
- The interpreter and the irparallel together caused an annoying error. 
- To fix the error (specifically for refseq first), the following block of code was added to the irparallel script:
```bash
COMMAND=$1 
EXPLODED=($COMMAND) 
EXENAME=$(echo ${EXPLODED[0]} | sed 's/\"//g') 
if [[ $(basename $EXENAME .py) == $(basename $EXENAME) ]]; then  
 COMMAND2="$COMMAND" 
else 
 REST="\"$(echo ${EXPLODED[@]:1} | sed 's/\"//g')\"";  
 COMMAND2="$USE_PYTHON_INTERPRETER ${EXPLODED[0]} $REST" 
fi 
```

#### Wednesday (29/05/2024)

##### Using the fixed script for refseq to get the UniProt and GenPept parsing working  
- Running the GenPept parsing step while trying to get the UniProt parsing step working 
- Trying to get the irdata_parse_uniprot.sh compatible to run the irparallel script. Which is hard because the basis of the command is a whole lot bigger with an extra pipeline and two python scripts instead of one


#### Thursday (29/05/2024)

##### Using the fixed script for refseq to get the UniProt and GenPept parsing working  
- Running the GenPept parsing step while trying to get the UniProt parsing step working 
- Trying to get the irdata_parse_uniprot.sh compatible to run the irparallel script. 


#### Friday (30/05/2024)
##### Trying to get the irdata_parse_uniprot.sh compatible to run the irparallel script. 
- Not succeeding at this and deciding to start all over again, just before the step where the python interpreter starts getting used. Cleaning up the files were there are traces of the usage of a virtual environment 

## Week 7
#### Monday (03/06/2024)
##### Running into an error while running irparse.yml
- Cannot locate the irdata logs directory.  
- the problem could be tracked down with "grep -r" till it could be concluded that it occured here:
```bash
if [ ! -e "$LOGS" ] && [ ! "$INSPECTONLY" ]; then echo "Cannot locate the irdata logs directory." 1>&2 exit 1 fi 
```
it was trying to write to a directory that didn’t exist. 
- solution, changing the $LOGS into a directory that does exist (on the mnt disk)
- Cleaning the playbooks up so all the signs to an external environment are gone 

 
#### Tuesday (04/06/2024)
##### Running into an error while running irparse.yml
- cannot create directory ‘/home/elias.steyaert/.ansible/tmp/ansible-tmp-1717502869.8542364-50434-182160768545910’: No space left on device 
Making another ansibl.cfg file but now on a different directory so that directory does also have a config file
- Irparse didn’t work, no error or message on why it was happening -> in irparallel there was a variable being used which didn’t exist anymore 

##### manual QC for the refseq parsing step
- Following the parsing step of the refseq database to make up a conclusion if everything is parsed or not 


#### Wednesday (05/06/2024)
##### Running irimport
- Running irimport for the first time, first with all the jobs at once, after that only with the Athaliana  
- Rapidly showing new errors


#### Thursday (06/06/2024)
##### Trying to download “gene”
- Which constantly fails or gives error messages like: Can’t find the job” while all the right things are included. 

##### The "/" directory was full again, this time not because of temporary files
- Figuring out a good CLI command to find the right output to see where the largest files are: 
```bash
sudo du -hS / | grep -v "^/mnt" | sort -h -r | head -n 25 | more 
```
- The problem was a random /tmp file in the /home/irefindex/usr/bin directory


#### Friday (07/06/2024)
##### Checking for each downloaded source that everything is downloaded 
- This is done manually, the size ("ls -lh" into the downloaded folder) is compared with how big the databases are online (the source)
- Trying to succesfully download Uniprot, which always stops at a maximum of 16G. Trying to adjust the custom settings of the job without succeeding 


## Week 8
#### Monday (10/06/2024)
##### Trying to get the database Uniprot fully downloaded, as of now it always stops around 16GB of the 171GB. 
- For example tried the code:
```bash
# Run jobs for uniprot 
- name: Run jobs for uniprot 
ansible.builtin.command: "./irdownload {{ item.name | upper }}" 
args: 
chdir: "/home/irefindex/usr/bin" 
async: "{{ item.download_runner_async | default(2000) }}" 
poll: 0 
register: result 
retries: "{{ item.download_retries | default(60) }}" 
until: result.finished 
delay: "{{ item.download_delay | default(100) }}" 
loop: "{{ jobs }}" 
when: item.name == "uniprot" 
```
- It finally went on to download all the GB's, let this run in a tmux session because downloading 172GB takes its time


#### Tuesday (11/06/2024)
##### Adjusting the playbook so the parsing of Uniprot can’t be timed-out by ansible. 
- Parsing the Uniprot data, this took more than 24 houres and so was done in a tmux session

#### Parsing Uniprot and trying to run irimport
- Running irimport on the jobs that were succesfull after downloading and parsing and having a look what goes wrong (the data gets written to the “/” disk instead on a disk with more space) 


#### Wednesday (12/06/2024)
##### Working on powerpoint presentation 
- Presenting this ppt and answering questions about the project
- Going over the evaluation report together with James Collier (supervisor)

##### adding code in irinit 
- This is done so the data from irimport is written on the disk and not in the home directory (adjusting the postgresql.conf file through ansible so its automated) 







### Trainee documentation plan (TDP)

#####Tentative planning:
Which tasks will be performed during the traineeship (briefly)?
The main task of this internship is to go look at all the steps involved in the iRefIndex pipeline. This pipeline is like a big system for gathering and organizing information about how proteins interact with each other. It collects data from different places and puts it all together in one place. By going through each part of this process, we want to improve the automatization of using this dataset. That means fewer mistakes and quicker fixes if something goes wrong. This helps other users to get the protein interaction data they need faster and with fewer errors.

##### Data management: 
Use the FAIR principle (Table 2) as a guide to store and structure your data.
The structure of my data is stored in my GitHub, in its own repository. This can be found in the following link: https://github.com/EliasSteyaert/stage-VIB-irefindex.git

##### Which aspects of the FAIR principle can be applied to your documentation system?
All of the aspects of the FAIR principle can be applied: 
- Findability: The data used originates from the iRefIndex and Complex Portal databases. iRefIndex data, available at ‘https://irefindex.vib.be/wiki/index.php/iRefIndex', provides unique identifiers for interactors, taxonomy identifiers, interaction types, and interaction sources. Each protein interaction record and participant protein has a corresponding key.
 - Accesiblity: The iRefIndex database, available at 'https://irefindex.vib.be/wiki/index.php/iRefIndex', provides version 19.0 data in PSI-MITAB format, specifically for human (taxon id: 9606). The dataset can be accessed at 'https://storage.googleapis.com/irefindex-data/archive/release_19.0/psi_mitab/MITAB2.6/9606.mitab.08-22-2022.txt'. Additionally, the dataset for all organisms in iRefIndex is available at 'https://storage.googleapis.com/irefindex-data/archive/release_19.0/psi_mitab/MITAB2.6/All.mitab.08-22-2022.txt'.
- Interoperability: The iRefIndex data is accessible in PSI-MITAB 2.6 tab-delimited format.
- Reproducibility: the iRefIndex data can be reused using the method that can be found on the VIB GitHub: https://github.com/EliasSteyaert/stage-VIB-irefindex.git

##### Traceability of steps and methods:
Which platform or application (e.g. Markdown pages on Git, Word document ...) will be used to document the project steps and progression in a traceable manner? 
There is a Rmarkdown file in my GitHub repository. In this Rmarkdown file is my ETN (Electronic Traineeship Notebook), where there is a description of the actions performed during each day.

##### Version control of code:
Which Git repository will be used to store the code?
The code will be stored in my own GitHub repository which is a clone of the fork of the original project of the VIB. The GitHub repository can be found with the following link: https://github.com/EliasSteyaert/stage-VIB-irefindex.git
How will the repository be made available for the internal and external supervisors?
The status of the repository is set on public. Everyone can see the code on my GitHub repository.


### The Learning Outcome (LO)

##### Development goal:
Trying to learn/become better at using ansible so I can automate processes easier.

##### Development activity:
I will be working with ansible playbooks, find errors and parts of it that don’t work properly and fix them so it can be more automated.

##### Desired results:
Being able to make a fully running ansible playbook so that other users don’t have to do anything except to run the playbook.

##### Schedule:
These activities will be performed throughout the internship (on daily basis).

##### Necessary support and facilities:
Normally, all this should be done in the traineeship and its 250 hours. Nothing should be bought for this goal to be achieved.

##### SMART-principle:
- Specific: learning how to use ansible and make my own playbooks.
- Measurable: At the end of the traineeship I should be able to make my own working ansible playbook.
- Achievable: As I’m working daily with ansible for my traineeship, I should be able to achieve this goal.
- Relevant: In the context of the traineeship, this learning outcome is relevant.
- Time-bound: This should be achieved by the end of the traineeship.
